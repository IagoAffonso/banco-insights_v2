"""
ğŸ” Financial Data Sanity Checks - Banco Insights 2.0

This script implements comprehensive sanity checks for financial data integrity:
1. Balance Sheet Equation: Assets = Liabilities + Equity
2. Data completeness and consistency validation
3. Outlier detection and flagging
4. Cross-table consistency checks
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import warnings

warnings.filterwarnings('ignore')

class FinancialDataSanityChecker:
    """
    Comprehensive financial data integrity validation.
    """
    
    def __init__(self):
        self.data_dir = Path("data_restructured")
        self.results = {
            'balance_sheet_checks': [],
            'completeness_checks': [],
            'outlier_flags': [],
            'consistency_checks': []
        }
        
    def load_available_data(self) -> Dict[str, pd.DataFrame]:
        """Load all available restructured data."""
        
        print("ğŸ“‚ LOADING AVAILABLE DATA FOR SANITY CHECKS")
        print("=" * 50)
        
        data = {}
        
        # Core tables
        core_tables_path = self.data_dir / "core_tables"
        if core_tables_path.exists():
            for csv_file in core_tables_path.glob("*.csv"):
                table_name = csv_file.stem
                try:
                    df = pd.read_csv(csv_file)
                    data[table_name] = df
                    print(f"âœ… Loaded {table_name}: {len(df):,} records, {df['CodInst'].nunique():,} institutions")
                except Exception as e:
                    print(f"âŒ Error loading {table_name}: {e}")
        
        # Calculated metrics
        metrics_path = self.data_dir / "calculated_metrics"
        if metrics_path.exists():
            for csv_file in metrics_path.glob("*.csv"):
                table_name = csv_file.stem
                try:
                    df = pd.read_csv(csv_file)
                    data[table_name] = df
                    print(f"âœ… Loaded {table_name}: {len(df):,} records")
                except Exception as e:
                    print(f"âŒ Error loading {table_name}: {e}")
        
        print(f"\\nğŸ“Š Total datasets loaded: {len(data)}")
        return data
    
    def check_balance_sheet_equation(self, data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Check fundamental balance sheet equation: Assets = Liabilities + Equity
        Using available data from resumo_quarterly.
        """
        
        print("\\nâš–ï¸  BALANCE SHEET EQUATION VALIDATION")
        print("=" * 50)
        
        if 'resumo_quarterly' not in data:
            print("âŒ resumo_quarterly data not available for balance sheet checks")
            return {'status': 'failed', 'reason': 'missing_data'}
        
        df = data['resumo_quarterly'].copy()
        print(f"ğŸ“Š Analyzing {len(df):,} records for balance sheet integrity")
        
        # Available columns in resumo data
        available_cols = df.columns.tolist()
        print(f"ğŸ’¡ Available columns: {available_cols}")
        
        # We can validate based on what we have
        checks = {}
        
        # Check 1: Asset and Equity consistency
        if 'Ativo_Total' in df.columns and 'Patrimonio_Liquido' in df.columns:
            
            # Basic validation: Equity should be positive and less than total assets
            valid_equity = (df['Patrimonio_Liquido'] > 0) & (df['Patrimonio_Liquido'] <= df['Ativo_Total'])
            equity_validity_rate = valid_equity.sum() / len(df) * 100
            
            checks['equity_validation'] = {
                'total_records': len(df),
                'valid_equity_records': valid_equity.sum(),
                'validity_rate': equity_validity_rate,
                'status': 'pass' if equity_validity_rate > 90 else 'warning'
            }
            
            print(f"ğŸ›ï¸  Equity Validation:")
            print(f"   â€¢ Valid records: {valid_equity.sum():,}/{len(df):,} ({equity_validity_rate:.1f}%)")
            
            # Flag institutions with negative equity
            negative_equity = df[df['Patrimonio_Liquido'] <= 0]
            if len(negative_equity) > 0:
                print(f"âš ï¸  Institutions with negative/zero equity: {len(negative_equity):,}")
                print(f"   Sample negative equity cases:")
                for idx, row in negative_equity.head(3).iterrows():
                    print(f"   â€¢ {row['NomeInstituicao'][:40]} ({row['AnoMes_Q']}): R$ {row['Patrimonio_Liquido']:,.0f}")
        
        # Check 2: Asset and Captacoes relationship
        if 'Ativo_Total' in df.columns and 'Captacoes' in df.columns:
            
            # Captacoes should generally be less than total assets
            valid_captacoes = (df['Captacoes'] >= 0) & (df['Captacoes'] <= df['Ativo_Total'] * 1.5)  # Allow 50% buffer
            captacoes_validity_rate = valid_captacoes.sum() / len(df) * 100
            
            checks['captacoes_validation'] = {
                'total_records': len(df),
                'valid_captacoes_records': valid_captacoes.sum(),
                'validity_rate': captacoes_validity_rate,
                'status': 'pass' if captacoes_validity_rate > 85 else 'warning'
            }
            
            print(f"\\nğŸ’° CaptaÃ§Ãµes Validation:")
            print(f"   â€¢ Valid records: {valid_captacoes.sum():,}/{len(df):,} ({captacoes_validity_rate:.1f}%)")
            
            # Check captacoes-to-assets ratio distribution
            captacoes_ratio = df['Captacoes'] / df['Ativo_Total']
            print(f"   â€¢ CaptaÃ§Ãµes/Assets ratio - Mean: {captacoes_ratio.mean():.1%}, Median: {captacoes_ratio.median():.1%}")
        
        # Check 3: Profitability sanity
        if 'Lucro_Liquido' in df.columns and 'Ativo_Total' in df.columns:
            
            # Calculate basic ROA for sanity
            roa_basic = (df['Lucro_Liquido'] / df['Ativo_Total']) * 100
            
            # Flag extremely high or low ROAs (outside -50% to +50%)
            reasonable_roa = (roa_basic >= -50) & (roa_basic <= 50)
            roa_validity_rate = reasonable_roa.sum() / len(df[df['Lucro_Liquido'].notna()]) * 100
            
            checks['profitability_validation'] = {
                'total_records': len(df[df['Lucro_Liquido'].notna()]),
                'reasonable_roa_records': reasonable_roa.sum(),
                'validity_rate': roa_validity_rate,
                'roa_mean': roa_basic.mean(),
                'roa_median': roa_basic.median(),
                'status': 'pass' if roa_validity_rate > 95 else 'warning'
            }
            
            print(f"\\nğŸ“ˆ Profitability Validation:")
            print(f"   â€¢ Reasonable ROA records: {reasonable_roa.sum():,}/{len(df[df['Lucro_Liquido'].notna()]):,} ({roa_validity_rate:.1f}%)")
            print(f"   â€¢ ROA distribution - Mean: {roa_basic.mean():.2f}%, Median: {roa_basic.median():.2f}%")
            
            # Show extreme cases
            extreme_roa = df[~reasonable_roa & df['Lucro_Liquido'].notna()]
            if len(extreme_roa) > 0:
                print(f"âš ï¸  Extreme ROA cases: {len(extreme_roa):,}")
                for idx, row in extreme_roa.head(3).iterrows():
                    basic_roa = (row['Lucro_Liquido'] / row['Ativo_Total']) * 100
                    print(f"   â€¢ {row['NomeInstituicao'][:40]} ({row['AnoMes_Q']}): {basic_roa:.1f}%")
        
        self.results['balance_sheet_checks'] = checks
        return checks
    
    def check_data_completeness(self, data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Validate data completeness and coverage.
        """
        
        print("\\nğŸ“Š DATA COMPLETENESS VALIDATION")
        print("=" * 50)
        
        completeness_results = {}
        
        for table_name, df in data.items():
            
            print(f"\\nğŸ” Analyzing {table_name}:")
            
            # Basic completeness metrics
            total_records = len(df)
            total_institutions = df['CodInst'].nunique() if 'CodInst' in df.columns else 0
            
            # Check for missing values in key columns
            key_columns = []
            missing_analysis = {}
            
            for col in df.columns:
                if col in ['CodInst', 'NomeInstituicao', 'AnoMes_Q']:
                    key_columns.append(col)
                elif any(keyword in col.lower() for keyword in ['ativo', 'patrimonio', 'lucro', 'roe', 'roa']):
                    key_columns.append(col)
            
            for col in key_columns:
                missing_count = df[col].isna().sum()
                missing_rate = (missing_count / total_records) * 100
                missing_analysis[col] = {
                    'missing_count': missing_count,
                    'missing_rate': missing_rate,
                    'status': 'good' if missing_rate < 5 else 'warning' if missing_rate < 20 else 'critical'
                }
                
                print(f"   â€¢ {col}: {missing_count:,}/{total_records:,} missing ({missing_rate:.1f}%)")
            
            # Date range analysis
            if 'AnoMes_Q' in df.columns:
                date_range = f"{df['AnoMes_Q'].min()} to {df['AnoMes_Q'].max()}"
                unique_periods = df['AnoMes_Q'].nunique()
                print(f"   â€¢ Date range: {date_range} ({unique_periods} unique periods)")
            
            completeness_results[table_name] = {
                'total_records': total_records,
                'total_institutions': total_institutions,
                'missing_analysis': missing_analysis,
                'date_coverage': date_range if 'AnoMes_Q' in df.columns else 'N/A'
            }
        
        self.results['completeness_checks'] = completeness_results
        return completeness_results
    
    def detect_outliers(self, data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Detect statistical outliers in financial metrics.
        """
        
        print("\\nğŸš¨ OUTLIER DETECTION")
        print("=" * 50)
        
        outlier_results = {}
        
        # Focus on resumo_quarterly for outlier detection
        if 'resumo_quarterly' in data:
            df = data['resumo_quarterly'].copy()
            
            # Define financial metrics to check
            financial_metrics = []
            for col in df.columns:
                if col in ['Ativo_Total', 'Patrimonio_Liquido', 'Captacoes', 'Lucro_Liquido']:
                    financial_metrics.append(col)
            
            for metric in financial_metrics:
                
                # Calculate IQR-based outliers
                Q1 = df[metric].quantile(0.25)
                Q3 = df[metric].quantile(0.75)
                IQR = Q3 - Q1
                
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df[(df[metric] < lower_bound) | (df[metric] > upper_bound)]
                outlier_rate = len(outliers) / len(df[df[metric].notna()]) * 100
                
                outlier_results[metric] = {
                    'outlier_count': len(outliers),
                    'outlier_rate': outlier_rate,
                    'q1': Q1,
                    'q3': Q3,
                    'iqr': IQR,
                    'lower_bound': lower_bound,
                    'upper_bound': upper_bound,
                    'status': 'normal' if outlier_rate < 10 else 'high'
                }
                
                print(f"\\nğŸ“Š {metric} Outlier Analysis:")
                print(f"   â€¢ Outliers: {len(outliers):,}/{len(df[df[metric].notna()]):,} ({outlier_rate:.1f}%)")
                print(f"   â€¢ Range: R$ {lower_bound:,.0f} to R$ {upper_bound:,.0f}")
                
                # Show sample outliers
                if len(outliers) > 0:
                    print(f"   Sample outliers:")
                    for idx, row in outliers.head(3).iterrows():
                        print(f"   â€¢ {row['NomeInstituicao'][:30]} ({row['AnoMes_Q']}): R$ {row[metric]:,.0f}")
        
        self.results['outlier_flags'] = outlier_results
        return outlier_results
    
    def check_ttm_consistency(self, data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Validate TTM calculations consistency.
        """
        
        print("\\nğŸ”„ TTM CALCULATION CONSISTENCY")
        print("=" * 50)
        
        ttm_checks = {}
        
        if 'basic_ttm_ratios_quarterly' in data and 'resumo_quarterly' in data:
            
            ttm_df = data['basic_ttm_ratios_quarterly']
            resumo_df = data['resumo_quarterly']
            
            print(f"ğŸ“Š Validating {len(ttm_df):,} TTM calculations")
            
            # Check 1: ROE/ROA reasonableness
            reasonable_roe = (ttm_df['ROE_TTM'].between(-100, 100)) | ttm_df['ROE_TTM'].isna()
            reasonable_roa = (ttm_df['ROA_TTM'].between(-50, 50)) | ttm_df['ROA_TTM'].isna()
            
            roe_validity = reasonable_roe.sum() / len(ttm_df) * 100
            roa_validity = reasonable_roa.sum() / len(ttm_df) * 100
            
            ttm_checks['ratio_reasonableness'] = {
                'roe_validity_rate': roe_validity,
                'roa_validity_rate': roa_validity,
                'status': 'pass' if min(roe_validity, roa_validity) > 95 else 'warning'
            }
            
            print(f"âœ… TTM Ratio Validity:")
            print(f"   â€¢ ROE within reasonable range: {reasonable_roe.sum():,}/{len(ttm_df):,} ({roe_validity:.1f}%)")
            print(f"   â€¢ ROA within reasonable range: {reasonable_roa.sum():,}/{len(ttm_df):,} ({roa_validity:.1f}%)")
            
            # Check 2: TTM vs point-in-time comparison for recent data
            latest_period = ttm_df['AnoMes_Q'].max()
            latest_ttm = ttm_df[ttm_df['AnoMes_Q'] == latest_period]
            latest_resumo = resumo_df[resumo_df['AnoMes_Q'] == latest_period]
            
            if len(latest_ttm) > 0 and len(latest_resumo) > 0:
                
                # Merge for comparison
                merged = latest_ttm.merge(latest_resumo, on=['CodInst', 'AnoMes_Q'], suffixes=('_ttm', '_resumo'))
                
                if len(merged) > 0:
                    # Calculate point-in-time ROE for comparison
                    merged['ROE_PIT'] = (merged['Lucro_Liquido'] / merged['Patrimonio_Liquido']) * 100
                    
                    # Compare TTM vs Point-in-time
                    valid_comparisons = merged[merged['ROE_TTM'].notna() & merged['ROE_PIT'].notna()]
                    
                    if len(valid_comparisons) > 0:
                        correlation = valid_comparisons['ROE_TTM'].corr(valid_comparisons['ROE_PIT'])
                        mean_diff = (valid_comparisons['ROE_TTM'] - valid_comparisons['ROE_PIT']).mean()
                        
                        ttm_checks['ttm_vs_pit_comparison'] = {
                            'correlation': correlation,
                            'mean_difference': mean_diff,
                            'comparison_count': len(valid_comparisons),
                            'status': 'good' if abs(correlation) > 0.5 else 'warning'
                        }
                        
                        print(f"\\nğŸ“ˆ TTM vs Point-in-Time Comparison ({latest_period}):")
                        print(f"   â€¢ Valid comparisons: {len(valid_comparisons):,}")
                        print(f"   â€¢ Correlation: {correlation:.3f}")
                        print(f"   â€¢ Mean difference (TTM - PIT): {mean_diff:+.2f} percentage points")
        
        else:
            print("âŒ TTM data not available for consistency checks")
        
        self.results['consistency_checks'] = ttm_checks
        return ttm_checks
    
    def generate_sanity_check_report(self) -> str:
        """
        Generate comprehensive sanity check report.
        """
        
        report = []
        report.append("ğŸ” FINANCIAL DATA SANITY CHECK REPORT")
        report.append("=" * 50)
        report.append("")
        
        # Summary
        all_checks_passed = True
        warnings_count = 0
        critical_issues = 0
        
        # Analyze results
        for check_category, checks in self.results.items():
            if isinstance(checks, dict):
                for check_name, check_result in checks.items():
                    if isinstance(check_result, dict) and 'status' in check_result:
                        status = check_result['status']
                        if status in ['warning', 'high']:
                            warnings_count += 1
                        elif status in ['critical', 'failed']:
                            critical_issues += 1
                            all_checks_passed = False
        
        report.append(f"ğŸ“Š OVERALL ASSESSMENT:")
        if all_checks_passed and warnings_count == 0:
            report.append(f"   âœ… ALL CHECKS PASSED - Data integrity excellent")
        elif critical_issues == 0:
            report.append(f"   âš ï¸  MINOR ISSUES DETECTED - {warnings_count} warnings")
        else:
            report.append(f"   âŒ CRITICAL ISSUES FOUND - {critical_issues} critical, {warnings_count} warnings")
        
        report.append("")
        report.append("ğŸ“‹ DETAILED RESULTS:")
        
        # Add detailed results
        for category, results in self.results.items():
            if results:
                report.append(f"\\n{category.upper().replace('_', ' ')}:")
                report.append("-" * 30)
                
                if isinstance(results, dict):
                    for key, value in results.items():
                        if isinstance(value, dict):
                            report.append(f"â€¢ {key}:")
                            for subkey, subvalue in value.items():
                                if subkey != 'status':
                                    report.append(f"  - {subkey}: {subvalue}")
                        else:
                            report.append(f"â€¢ {key}: {value}")
        
        return "\\n".join(report)
    
    def run_all_sanity_checks(self) -> Dict:
        """
        Execute all sanity checks and return results.
        """
        
        print("ğŸš€ STARTING COMPREHENSIVE SANITY CHECKS")
        print("=" * 60)
        
        # Load data
        data = self.load_available_data()
        
        if not data:
            print("âŒ No data available for sanity checks")
            return {'status': 'failed', 'reason': 'no_data'}
        
        # Run all checks
        balance_checks = self.check_balance_sheet_equation(data)
        completeness_checks = self.check_data_completeness(data)
        outlier_checks = self.detect_outliers(data)
        ttm_checks = self.check_ttm_consistency(data)
        
        # Generate report
        report = self.generate_sanity_check_report()
        
        # Save report
        report_path = Path("data_restructured/quality_assurance/sanity_check_report.txt")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\\nğŸ’¾ Sanity check report saved to: {report_path}")
        print("\\n" + report)
        
        return {
            'status': 'completed',
            'balance_checks': balance_checks,
            'completeness_checks': completeness_checks,
            'outlier_checks': outlier_checks,
            'ttm_checks': ttm_checks,
            'report_path': str(report_path)
        }

def main():
    """Execute sanity checks."""
    
    checker = FinancialDataSanityChecker()
    results = checker.run_all_sanity_checks()
    
    if results['status'] == 'completed':
        print("\\nğŸ‰ SANITY CHECKS COMPLETED!")
        print("âœ… Step 3 of data restructuring plan complete")
        print("ğŸš€ Ready to proceed with Supabase deployment cleanup")
    else:
        print("âŒ Sanity checks failed - review issues above")
    
    return results

if __name__ == "__main__":
    main()